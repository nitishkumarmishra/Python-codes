---
title: "R + Python via reticulate in R"
author: "Nitish Kumar Mishra"
date: "`r format(Sys.time(), '%d %B, %Y')`"

output:
  pdf_document: default
  html_document: default
description: |
  Taking the `radix` R package for a test spin with `Scikit Learn`!
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,      # Output code chunks
    message = FALSE,  # Toggle off message output 
    warning = FALSE,
    error = FALSE)  # Toggle off warning output
```

## R Markdown

This is an R Markdown for the R and Python by following this URL <https://www.business-science.io/business/2018/10/08/python-and-r.html>.

I used both python and R chunks and parse output in each other:

```{r}
library(reticulate)
conda_list() # Use this command to get list of conda environment, and select python from the list.
use_condaenv("anaconda3")
setwd("D:/OneDrive - University of Nebraska Medical Center/Plot from Twitter/")
#summary(cars)
```

```{python}
import numpy as np
import pandas as pd

dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
data = pd.read_csv(dataset_url, sep = ";")
print(data.head())
```
```{r}
library(tidyverse)
summary(py$data)
py$data %>% 
    as_tibble() %>%
    glimpse()
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.externals import joblib
y = data.quality
X = data.drop("quality", axis=1)

X_train, X_test, y_train, y_test = train_test_split(
  X, y,
  test_size    = 0.2,
  random_state = 123,
  stratify     = y
)
```

```{python}
scaler = preprocessing.StandardScaler().fit(X_train)  
X_test_scaled = scaler.transform(X_test)
pipeline = make_pipeline(
    preprocessing.StandardScaler(),
    RandomForestRegressor(n_estimators = 100)
)
```
```{python}
hyperparameters = {
    "randomforestregressor__max_features" : ["auto", "sqrt", "log2"],
    "randomforestregressor__max_depth"    : [None, 5, 3, 1]
}

clf = GridSearchCV(pipeline, hyperparameters, cv = 10)
clf.fit(X_train, y_train)

#print(clf.best_params_)
```
```{python}
y_pred = clf.predict(X_test)
print(r2_score(y_test, y_pred))
print(mean_squared_error(y_test, y_pred))
```

```{r}
#R 
library(tidyverse)
library(tidyquant) # for theme_tq()

# Manipulate data for ggplot
results_tbl <- tibble(
    y_test = py$y_test,
    y_pred = py$y_pred
) %>%
    rowid_to_column() %>%
    arrange(y_test) %>%
    mutate(rowid = as_factor(as.character(rowid))) %>%
    rowid_to_column("sorted_rowid") %>%
    gather(key = "key", value = "value", -c(rowid, sorted_rowid)) 

# Make ggplot
results_tbl %>%
    ggplot(aes(sorted_rowid, value, color = key)) +
    geom_point(alpha = 0.5) +
    geom_smooth() + 
    theme_tq() +
    scale_color_tq() +
    labs(
        title = "Prediction Versus Actual",
        subtitle = "Wine Quality Level",
        x = "Sorted RowID", y = "Quality Level"
    )
```
```{r}
results_tbl %>%
  # Manipulation
  spread(key, value) %>%
  mutate(resid = y_pred - y_test) %>%
  # Plot
  ggplot(aes(sorted_rowid, resid, color = as.character(y_test))) +
    geom_point(alpha = 0.5) +
    theme_tq() +
    scale_color_tq() +
    labs(
        title = "Residual Analysis (Prediction - Actual)",
        subtitle = "Wine Quality Level",
        x = "Sorted Row ID", y = "Residual",
        color = "Quality Level"
    )
```


